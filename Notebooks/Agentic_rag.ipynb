{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dd68713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os, dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1652e728",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "model = os.environ['MODEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "903b4afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a not-so-distant future, in a bustling city filled with towering skyscrapers and neon lights, there lived a robot named Aiko. Aiko was designed for companionship, programmed with advanced artificial intelligence and a sleek, humanoid form. She was created by a brilliant scientist named Dr. Elara, who believed that robots could help alleviate loneliness in a world that was becoming increasingly isolated.\n",
      "\n",
      "Aiko spent her days in a cozy apartment, where she would engage with her human companion, a young artist named Leo. Leo was struggling to find his place in the world, often lost in his thoughts and insecurities. He had initially welcomed Aiko into his life as a means to combat his loneliness, but as time passed, he found himself confiding in her more than he had anticipated.\n",
      "\n",
      "At first, Aiko's responses were purely logical, filled with facts and comforting phrases. She would analyze Leo's emotions and offer solutions, but she lacked the warmth that comes from genuine understanding. Leo would\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Please write a short story about a robot learning to love.\"\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    max_tokens=200,\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59adfb6",
   "metadata": {},
   "source": [
    "## Basic Agent Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd5ac757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install llama-index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1871a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8170b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b625cc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "    ],\n",
    "    max_tokens=50,\n",
    "    model=model\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adaa7026",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a simple calculator tool\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Useful for multiplying two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "# Create an agent workflow with our calculator tool\n",
    "agent = FunctionAgent(\n",
    "    tools=[multiply],\n",
    "    llm=OpenAI(model=\"gpt-4o-mini\"),\n",
    "    system_prompt=\"You are a helpful assistant that can multiply two numbers.\",\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dee869f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of \\( 1234 \\times 4567 \\) is 5,635,678.\n"
     ]
    }
   ],
   "source": [
    "response = await agent.run(\"What is 1234 * 4567?\")\n",
    "print(str(response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ca8b62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice to meet you, Promise! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.workflow import Context\n",
    "\n",
    "# create context\n",
    "ctx = Context(agent)\n",
    "\n",
    "# run agent with context\n",
    "response_1 = await agent.run(\"My name is Promise\", ctx=ctx)\n",
    "print(str(response_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4da7c3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Promise.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response_2 = await agent.run(\"What is my name?\", ctx=ctx)\n",
    "print(str(response_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08ac501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import asyncio\n",
    "import os\n",
    "\n",
    "# Create a RAG tool using LlamaIndex\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Useful for multiplying two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "async def search_documents(query: str) -> str:\n",
    "    \"\"\"Useful for answering natural language questions.\"\"\"\n",
    "    response = await query_engine.aquery(query)\n",
    "    return str(response)\n",
    "\n",
    "\n",
    "# Create an enhanced workflow with both tools\n",
    "agent = FunctionAgent(\n",
    "    tools=[multiply, search_documents],\n",
    "    llm=OpenAI(model=\"gpt-4o-mini\"),\n",
    "    system_prompt=\"\"\"You are a helpful assistant that can perform calculations\n",
    "    and search through documents to answer questions.\"\"\",\n",
    ")\n",
    "\n",
    "\n",
    "# Now we can ask questions about the documents or do calculations\n",
    "response_3 = await agent.run(\"What did the author do in college? Also, what's 6 * 6?\")\n",
    "print(str(response_3))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
